---
date: 2021-03-30 13:00:00
updated: 2021-04-06 11:48:00
typora-root-url: ..\..
---

# 深入理解Kafka: 核心设计与原理实践（未完结）

![](/images/image-2021-03-30-12.58.25.640.png)



# 5.1 文件目录布局

kafka文件目录中有很多文件，一般情况下我们只需要掌握`*.index`, `*.log`,`*.timeindex*`即可

<!-- more -->

![](/images/image-2021-03-30-13.04.23.883.png)

# 5.2 日志格式的演变

> 从0.8.x版本开始到现在的2.0.0版本，Kafka的消息格式也经历了3个版本：v0版本、v1版本和v2版本。

分区由一条条消息组成，如果消息设计的不够合理，分区的功能和性能会受到影响，过多的冗余导致储存增加、网络开销大、性能降低，缺少字段又会影响到<span style="color: red">日志的保存、切分策略</span>。

## V0版本的消息

右边是消息集，每个Record是一条消息，offset是偏移量，messagesize代表消息的长度。

![](/images/image-2021-03-30-13.11.25.916.png)

对于每个RECORD，他的字段如下

|     名称     |           功能           | 大小 |
| :----------: | :----------------------: | :--: |
|    crc32     | 消息内容的循环冗余校验值 |  4B  |
|    magic     |        消息版本号        |  1B  |
|  attributes  |       消息压缩算法       |  1B  |
|  key length  |        key的长度         |  4B  |
|     key      |           key            |  ？  |
| value length |       value的长度        |  4B  |
|    value     |          value           |  ？  |

我们注意到这里有一个压缩算法，这里其实很有趣，这个压缩算法指的是value的压缩算法，对于一条消息而言，什么时候需要压缩呢？

kafka不会对一条数据进行压缩,因为一条消息往往很小，压缩也不划算，kafka会对多条消息进行压缩，然后封装为一条新的消息。这时的key是无用的。

![](/images/image-2021-03-30-13.24.50.808.png)

另外内层消息的offset又可以从0开始编号了。

## V1版本消息

就多了一个时间戳

![](/images/image-2021-03-30-13.39.27.411.png)

## V2版本消息

V2版本引入了变长整型varints以及zigzag编码，这种编码对于越小的数据，他所占的空间越少，对于较大的数据，他所占的空间较多。有兴趣的读者可以自行查阅

![](/images/image-2021-03-30-13.27.13.649.png)

在v2版本中，message set改名为recordBatch，他也拥有了自己的头，在recordBatch中包含了多个record，其中的每个record与v1版本并无太大差异，我们注意到，他使用了大量的varint和delta，这个意思是很多数据是基于recordBatch中数据的相对值，这也导致了这些数往往很小，所以varint能发挥它最大的作用。

| 名称            |     状态     |              解释              | 大小   |
| --------------- | :----------: | :----------------------------: | ------ |
| length          | message size |           消息总长度           | 变长   |
| attributes      |     弃用     |                                | 1B     |
| timestamp delta |  timestamp   |           相对时间戳           | 变长   |
| offset delta    |    offset    |           相对offset           | 变长   |
| key length      |  key length  |                                | 变长   |
| key             |     key      |                                | 未知   |
| value length    | value length |                                | 变长   |
| value           |    value     |                                | 未知   |
| headers         |     新增     | 应用级拓展（可以储存了多个kv） | varint |

# 5.3 日志索引

> 偏移量索引文件用来建立消息偏移量（offset）到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置；时间戳索引文件则根据指定的时间戳（timestamp）来查找对应的偏移量信息。

> Kafka 中的索引文件以稀疏索引（sparse index）的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。



## 日志分段切分

>
>
>- 当前日志分段文件的大小超过了 broker 端参数log.segment.bytes 配置的值。log.segment.bytes参数的默认值为1073741824，即1GB。
>
>- 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于 log.roll.ms或log.roll.hours参数配置的值。如果同时配置了log.roll.ms和log.roll.hours参数，那么log.roll.ms的优先级高。默认情况下，只配置了log.roll.hours参数，其值为168，即7天。
>- 偏移量索引文件或时间戳索引文件的大小达到broker端参数log.index.size.max.bytes配置的值。log.index.size.max.bytes的默认值为10485760，即10MB。
>- 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于Integer.MAX_VALUE，即要追加的消息的偏移量不能转变为相对偏移量（offset-baseOffset＞Integer.MAX_VALUE）。



![image-2021-04-06 10.17.29.274](/images/image-2021-04-06-10.17.29.274.png)



![image-2021-04-06 10.17.56.430](/images/image-2021-04-06-10.17.56.430.png)

时间撮索引和偏移量索引是类似的

![image-2021-04-06 10.18.23.311](/images/image-2021-04-06-10.18.23.311.png)



# 5.4 日志清理

## 日志删除

按照一定的保留策略直接删除不符合条件的日志分段。

### 基于时间

查找是否有保留时间超过设定的阈值的分段

### 基于日志大小

查找是否有超过设定阈值的分段

### 基于偏移量

基于logStartOffset，如果一个分段的的最后一条日志的偏移量小于logStartOffset，这个分段可以删除。

即一个分段的起始偏移量小于等于logStartOffset，则这个分段前的分段都可以删除，因为低于logStartOffset的日志不会被消费了。

## 日志压缩

针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本。

参考redis的模式kv



# 5.5 磁盘存储

## 顺序写

> Kafka 在设计时采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，并且也不允许修改已写入的消息，这种方式属于典型的顺序写盘的操作，所以就算 Kafka使用磁盘作为存储介质，它所能承载的吞吐量也不容小觑。但这并不是让Kafka在性能上具备足够竞争力的唯一因素，

## 页缓存

操作系统把磁盘缓存到内存中，以便减少对磁盘的IO

> 对一个进程而言，它会在进程内部缓存处理所需的数据，然而这些数据有可能还缓存在操作系统的页缓存中，因此同一份数据有可能被缓存了两次。并且，除非使用Direct I/O的方式，否则页缓存很难被禁止。此外，用过Java的人一般都知道两点事实：对象的内存开销非常大，通常会是真实数据大小的几倍甚至更多，空间使用率低下；Java的垃圾回收会随着堆内数据的增多而变得越来越慢。基于这些因素，使用文件系统并依赖于页缓存的做法明显要优于维护一个进程内缓存或其他结构，至少我们可以省去了一份进程内部的缓存消耗，同时还可以通过结构紧凑的字节码来替代使用对象的方式以节省更多的空间。如此，我们可以在 32GB 的机器上使用28GB至30GB的内存而不用担心GC所带来的性能问题。此外，即使Kafka服务重启，页缓存还是会保持有效，然而进程内的缓存却需要重建。这样也极大地简化了代码逻辑，因为维护页缓存和文件之间的一致性交由操作系统来负责，这样会比进程内维护更加安全有效。

Kafka大量使用了页缓存，当然他也提供同步刷盘和间断性刷盘的功能。

## 零拷贝

从磁盘读取文件，然后发送到网卡，这是一个很复杂的功能，读取数据时，数据不会从磁盘直接读取到进程的地址空间，发送数据时数据也不会直接从进程的地址空间发送出去，他们都需要先经过内核。详见[这一篇blog](/QPI740.html#more)

![image-2021-04-06 10.38.26.057](/images/image-2021-04-06-10.38.26.057.png)

> 从上面的过程可以看出，数据平白无故地从内核模式到用户模式“走了一圈”，浪费了 2次复制过程：第一次是从内核模式复制到用户模式；第二次是从用户模式再复制回内核模式，即上面4次过程中的第2步和第3步。而且在上面的过程中，内核和用户模式的上下文的切换也是4次。

如果使用零拷贝技术，操作2和3就可以省去了，并节省了CPU大部分的时间，如下图

![image-2021-04-06 10.46.27.387](/images/image-2021-04-06-10.46.27.387.png)

# 6.1 协议设计

Kafka的每一个请求都用公共的请求头

![image-2021-04-06 10.51.23.311](/images/image-2021-04-06-10.51.23.311.png)

请求头有四个部位

| Field          | 备注                                 | 大小  |
| -------------- | ------------------------------------ | ----- |
| api_key        | API标识                              | int16 |
| api_vesion     | API版本号                            | int16 |
| correlation_id | 请求ID，服务端会在回复中加入相同的ID | int16 |
| client_id      | 客户端ID                             | 未知  |

响应头就很简单了，就一个correlation_id

![image-2021-04-06 11.10.14.695](/images/image-2021-04-06-11.10.14.695.png)



![image-2021-04-06 11.12.00.773](/images/image-2021-04-06-11.12.00.773.png)



# 时间轮

























